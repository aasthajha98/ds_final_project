{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1701653505600,
     "user": {
      "displayName": "Aastha Jha",
      "userId": "05959336164976946971"
     },
     "user_tz": 300
    },
    "id": "nll9KwQ--gze",
    "outputId": "76df7a63-8a77-4349-c569-7ac775a17564"
   },
   "outputs": [],
   "source": [
    "#install packages if necessary\n",
    "\n",
    "#!pip install youtube-data-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1701653512196,
     "user": {
      "displayName": "Aastha Jha",
      "userId": "05959336164976946971"
     },
     "user_tz": 300
    },
    "id": "4VLMRsEH-udt"
   },
   "outputs": [],
   "source": [
    "#set up packages\n",
    "import pandas as pd\n",
    "import requests # For downloading the website\n",
    "from bs4 import BeautifulSoup # For parsing the website\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import time # To put the system to sleep\n",
    "import random # for random numbers\n",
    "\n",
    "from youtube_api import YouTubeDataAPI\n",
    "from youtube_api.youtube_api_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i58xIy5-k-s"
   },
   "outputs": [],
   "source": [
    "#insert your own API Key here\n",
    "# load keys from  environmental var\n",
    "load_dotenv() # .env file in cwd\n",
    "youtube_api = os.environ.get(\"api_key\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-yAog6p-oWy"
   },
   "outputs": [],
   "source": [
    "def video_info (search_term, max_res):\n",
    "    '''\n",
    "    This function takes in a search term and returns the information for the first N videos in a datafram\n",
    "    search_term: str - what you are looking up in youtube\n",
    "    max_res: int - the number of to return\n",
    "    '''\n",
    "    videos = pd.DataFrame(yt.search(q= search_term, max_results= max_res))\n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1icZl2BAKwg"
   },
   "outputs": [],
   "source": [
    "def get_comments (video_ids):\n",
    "    \"\"\"\n",
    "    Fetches comments for a list of YouTube video IDs.\n",
    "\n",
    "    Parameters:\n",
    "    - video_ids (list): A list of YouTube video IDs for which comments will be fetched.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing the comments for the specified videos.\n",
    "      Columns include 'comment_id', 'comment_text', 'comment_like_count',\n",
    "      'comment_publish_date', 'comment_date', and any additional fields provided by\n",
    "      the YouTube API.\n",
    "\n",
    "    Note:\n",
    "    - The 'comment_publish_date' field is converted to a human-readable date format\n",
    "      ('%Y-%m-%d %H:%M:%S UTC') and stored in the 'comment_date' column.\n",
    "    - Comments for videos that encounter errors during retrieval are skipped.\n",
    "      Any exception that occurs during retrieval is caught and ignored.\n",
    "\n",
    "    Example:\n",
    "    >>> video_ids = ['abc123', 'def456']\n",
    "    >>> comments_df = get_comments(video_ids)\n",
    "    \"\"\"\n",
    "    list_comments = []\n",
    "    for video_id in video_ids:\n",
    "    try:\n",
    "        comments = yt.get_video_comments(video_id )\n",
    "        list_comments.append(pd.DataFrame(comments))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    # concat\n",
    "    comments = pd.concat(list_comments)\n",
    "    comments['comment_date'] = [datetime.utcfromtimestamp(i).strftime('%Y-%m-%d %H:%M:%S UTC') for i in comments['comment_publish_date']]\n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNxvVMeDAMgr"
   },
   "outputs": [],
   "source": [
    "def full_data_frame(list_of_games, max_res):\n",
    "    \"\"\"\n",
    "    Fetches comments for multiple games and constructs a comprehensive DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - list_of_games (list): A list of game titles for which comments will be fetched.\n",
    "    - max_res (int): The maximum number of results to retrieve per game.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A DataFrame containing comments for videos associated with\n",
    "      the specified list of games. The DataFrame includes columns such as 'comment_id',\n",
    "      'comment_text', 'comment_like_count', 'comment_publish_date', 'comment_date',\n",
    "      'game', and any additional fields provided by the YouTube API.\n",
    "\n",
    "    Note:\n",
    "    - The 'comment_publish_date' field is converted to a human-readable date format\n",
    "      ('%Y-%m-%d %H:%M:%S UTC') and stored in the 'comment_date' column.\n",
    "    - Each row in the resulting DataFrame corresponds to a comment from a video related\n",
    "      to a specific game.\n",
    "    - Errors encountered during video information retrieval or comment fetching for a\n",
    "      particular game are printed but do not interrupt the process.\n",
    "\n",
    "    Example:\n",
    "    >>> list_of_games = ['Game1', 'Game2']\n",
    "    >>> max_res = 10\n",
    "    >>> comments_df = full_data_frame(list_of_games, max_res)\n",
    "    \"\"\"\n",
    "    game_title = []\n",
    "    main_df = []\n",
    "    for game in list_of_games:\n",
    "    print(game)\n",
    "    videos = video_info(game, max_res)\n",
    "    print(videos['video_id'][0])\n",
    "    comments = get_comments(videos['video_id'])\n",
    "    game_title += [game for i in range(len(comments))]\n",
    "    #game_title.append(game_labels)\n",
    "    #print(game_title)\n",
    "    main_df.append(comments)\n",
    "    df = pd.concat(main_df)\n",
    "    df['game'] = game_title\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0Md58vhAhgI"
   },
   "outputs": [],
   "source": [
    "#set up the parameters\n",
    "#list of search terms\n",
    "game_list = [\"FIFA Women's World Cup 2023 Group Stage USA vs Vietnam\", \"FIFA Women's World Cup 2023 Group Stage USA vs Netherlands\",\n",
    "                   \"FIFA Women's World Cup 2023 Group Stage USA vs Portugal\", \"FIFA Women's World Cup 2023 Round of 16 USA vs Sweden\"]\n",
    "\n",
    "max_res = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZLxxl62AvUg"
   },
   "outputs": [],
   "source": [
    "#scrape comment data from youtube\n",
    "comment_df = full_data_frame(game_list, max_res)\n",
    "\n",
    "comment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read out comments as a csv\n",
    "comment_df.to_csv('raw_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPF2NyldeHtyJhT8PYvWXii",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
